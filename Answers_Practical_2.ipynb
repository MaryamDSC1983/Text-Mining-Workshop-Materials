{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c839ac88-5640-4c00-a7ac-82c05e9d7758",
   "metadata": {},
   "source": [
    "# Practical 2: Genre Classification with sklearn\n",
    "### Instructor: Dr. Maryam Movahedifar\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
    "  <span style=\"display: flex; align-items: center;\">\n",
    "    <b>Applied Text Mining - University of Bremen - Data Science Center</b>\n",
    "  </span>\n",
    "  <div style=\"display: flex; align-items: center; margin-left: auto;\">\n",
    "    <img src=\"Uni_Logo.png\" alt=\"Uni Logo\" style=\"width: 100px; margin-right: 10px;\">\n",
    "    <img src=\"DSC_Logo.png\" alt=\"DSC Logo\" style=\"width: 150px;\">\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72850182-3646-4073-babe-942ea8f30301",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **Install the requiered libraries. Upload the \"book_reviews.csv\" from your machine. This file contains 10,000 English language book reviews from Goodreads, with genre, age, and star rating labels. Uploading may take a minute or so.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f722cba-a96c-48da-b9c3-510cfd75c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q scikit-learn -q numpy==1.24.0 gensim==4.3.3 spacy==3.5.1 nltk --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e6b3766-1bee-4d9e-9e9d-30844fb3c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "import string\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a6942-9e10-439d-b974-b622c4350ca0",
   "metadata": {},
   "source": [
    "2. **Load the .csv file into a Pandas dataframe. This makes it easy to acess and filter data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1e98bb6-14e4-40a4-b9e1-b4fafec073f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_no</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>id</th>\n",
       "      <th>age_category</th>\n",
       "      <th>book_genre</th>\n",
       "      <th>rating_no.1</th>\n",
       "      <th>tokenised_text</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>284434</td>\n",
       "      <td>review_244526687</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Popular fiction - general</td>\n",
       "      <td>1.0</td>\n",
       "      <td>like adult book concept simply ya spoiler exam...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30788</td>\n",
       "      <td>review_528067373</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Literary fiction</td>\n",
       "      <td>1.0</td>\n",
       "      <td>okay read college maybe little biased rating l...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>84989</td>\n",
       "      <td>review_3210428778</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Literary fiction</td>\n",
       "      <td>1.0</td>\n",
       "      <td>remember read book club hating probably chance...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>61511</td>\n",
       "      <td>review_112612281</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Literary fiction</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yeah star cause know like make like plus depre...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>112948</td>\n",
       "      <td>review_380001099</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Literary fiction</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assign book brit lit class read email teacher ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating_no  Unnamed: 1                 id age_category  \\\n",
       "0        1.0      284434   review_244526687        Adult   \n",
       "1        1.0       30788   review_528067373        Adult   \n",
       "2        1.0       84989  review_3210428778        Adult   \n",
       "3        1.0       61511   review_112612281        Adult   \n",
       "4        1.0      112948   review_380001099        Adult   \n",
       "\n",
       "                  book_genre  rating_no.1  \\\n",
       "0  Popular fiction - general          1.0   \n",
       "1           Literary fiction          1.0   \n",
       "2           Literary fiction          1.0   \n",
       "3           Literary fiction          1.0   \n",
       "4           Literary fiction          1.0   \n",
       "\n",
       "                                      tokenised_text  n_tokens  \n",
       "0  like adult book concept simply ya spoiler exam...        30  \n",
       "1  okay read college maybe little biased rating l...        21  \n",
       "2  remember read book club hating probably chance...        18  \n",
       "3  yeah star cause know like make like plus depre...        13  \n",
       "4  assign book brit lit class read email teacher ...        22  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('book_reviews.csv')\n",
    "# print the first five rows of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ed2a8-63b4-4508-8ca2-84136e2edbed",
   "metadata": {},
   "source": [
    "3. **Now you can construct the document-term matrix. The CountVectorizer class counts how often each word occurs in each document. Optionally, you can also pass ngram_range as a parameter, to see if combinations of multiple words are better predictors for ratings. Define the output of the fit_transform function on 'tokenised_text' as your feature matrix X, and the star ratings ('rating_no') as the variable y you're trying to predict.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbed3423-1e6f-403f-ae3b-aa8520829664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "# vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(data['tokenised_text'])\n",
    "y = data['book_genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf5ad4-faa8-48f9-8ddf-3330ca5cd104",
   "metadata": {},
   "source": [
    "*If there is issue in this part, to Fix the Issue in Jupyter:\n",
    "Restart the Kernel: After installing or updating packages in Jupyter, it's important to restart the kernel to make sure the changes take effect. To restart the kernel:\n",
    "Go to the Kernel menu in Jupyter. Click Restart Kernel.*\n",
    "\n",
    "    \n",
    "To inspect the words in the document-term matrix, you can call get_feature_names_out() on the vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9873f367-b66d-414c-ae40-ec011bfe3f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa' 'aaaaaaa' 'aaaaaaaahhhhh' 'aaaaah' 'aaaaand' 'aaaahhhhh' 'aaack'\n",
      " 'aaah' 'aaarrrgggh' 'aagggh' 'aaj' 'ab' 'aback' 'abacus' 'abandon'\n",
      " 'abandone' 'abandoned' 'abandonment' 'abasement' 'abasment']\n"
     ]
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names_out()\n",
    "print(words[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc88340-fd6b-4656-94d0-43a6f053a7fc",
   "metadata": {},
   "source": [
    "Alternatively, you could also use a `TfidfVectorizer`: this class counts how often a word occurs in a document and weighs it against how often the word occurs in the whole corpus. This is a way to eliminate words that are frequent but not very meaningful. You can play around with different vectorizers to see how they affect your results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e47ba07-b041-44c2-9c70-3d0b297509ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data['tokenised_text'])\n",
    "y = data['book_genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8523c3-6d79-4adf-8602-5fbb3735cec4",
   "metadata": {},
   "source": [
    "4. **Now we can define a baseline model: use the `DummyClassifier` to always predict the most frequent genre in the dataset.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba35feff-3fdb-4450-848d-6271d9287a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4991"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X, y)\n",
    "dummy_clf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa74b38e-0fac-4e7a-9bf3-f739653ef1b6",
   "metadata": {},
   "source": [
    "5. **After defining your document-term matrix, you can split the data into train- and test sets. Note that `random_state` is used so that the split will be the same for everyone in the group, such that different random selections don't cause slightly different results.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9b4dc88-2897-4db3-aefa-a2ec13b0bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f0a241-e86d-4700-82f4-93e71a7af557",
   "metadata": {},
   "source": [
    "6. **Now pick one of the following classifiers:**\n",
    "\n",
    "[K-Nearest Neighbor classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)  \n",
    "[Multinomial Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB)  \n",
    "[Support Vector Machine](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)  \n",
    "[Decision Tree Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)  \n",
    "[Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19f37324-8cc5-475e-9eb5-0515e70731bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with 3 neighbours: 0.5806060606060606 \n",
      "accuracy with 10 neighbours: 0.6466666666666666 \n",
      "accuracy with 100 neighbours: 0.6378787878787879\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "model = knn.fit(X_train, y_train)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "model2 = knn.fit(X_train, y_train)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=100)\n",
    "model3 = knn.fit(X_train, y_train)\n",
    "print('accuracy with 3 neighbours:', model.score(X_test, y_test),\n",
    "      '\\naccuracy with 10 neighbours:', model2.score(X_test, y_test),\n",
    "      '\\naccuracy with 100 neighbours:', model3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b52c286d-2ad2-458d-966d-b27d6e732a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with alpha=1: 0.5163636363636364 \n",
      "accuracy with alpha=10: 0.5051515151515151\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB(alpha=1)\n",
    "model = nb.fit(X_train, y_train)\n",
    "\n",
    "nb = MultinomialNB(alpha=10)\n",
    "model2 = nb.fit(X_train, y_train)\n",
    "print('accuracy with alpha=1:', model.score(X_test, y_test),\n",
    "      '\\naccuracy with alpha=10:', model2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f4c1d76-796c-48fb-b88d-20b459c67d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with default regularization: 0.7145454545454546 \n",
      "accuracy with more regularization: 0.6809090909090909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC(C=1.0)\n",
    "model = svm.fit(X_train, y_train)\n",
    "\n",
    "svm = LinearSVC(C=0.1)\n",
    "model2 = svm.fit(X_train, y_train)\n",
    "print('accuracy with default regularization:', model.score(X_test, y_test),\n",
    "      '\\naccuracy with more regularization:', model2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31d77e09-b986-44e3-aa81-601ec4112a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with maximum tree depth 5: 0.5896969696969697 \n",
      "accuracy with unlimited tree depth: 0.5281818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=5)\n",
    "model = tree.fit(X_train, y_train)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=None)\n",
    "model2 = tree.fit(X_train, y_train)\n",
    "print('accuracy with maximum tree depth 5:', model.score(X_test, y_test),\n",
    "      '\\naccuracy with unlimited tree depth:', model2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06544a81-8805-44bd-b370-8b7989d32041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with 3 trees: 0.5384848484848485 \n",
      "accuracy with 20 trees: 0.6236363636363637\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=3)\n",
    "model = rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=20)\n",
    "model2 = rfc.fit(X_train, y_train)\n",
    "print('accuracy with 3 trees:', model.score(X_test, y_test),\n",
    "      '\\naccuracy with 20 trees:', model2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b5e5fc-ea24-4634-9aef-c4de80c636d8",
   "metadata": {},
   "source": [
    "7. **Find the parameters which lead to best results. You can also automate this with [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), as shown below.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "007f3a77-806f-42bf-9027-889054301be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.656969696969697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cv': None,\n",
       " 'error_score': nan,\n",
       " 'estimator__algorithm': 'auto',\n",
       " 'estimator__leaf_size': 30,\n",
       " 'estimator__metric': 'minkowski',\n",
       " 'estimator__metric_params': None,\n",
       " 'estimator__n_jobs': None,\n",
       " 'estimator__n_neighbors': 5,\n",
       " 'estimator__p': 2,\n",
       " 'estimator__weights': 'uniform',\n",
       " 'estimator': KNeighborsClassifier(),\n",
       " 'n_jobs': None,\n",
       " 'param_grid': {'n_neighbors': [2, 20]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# set the search space for grid search. In this case, between 2 and 20 nearest neighbors\n",
    "parameters = {'n_neighbors': [2,20]}\n",
    "knn = KNeighborsClassifier()\n",
    "search = GridSearchCV(knn, parameters)\n",
    "search.fit(X_train, y_train)\n",
    "# the best score achieved\n",
    "print(search.score(X_test, y_test))\n",
    "# get_params() gives the parameters leading to this best score (in 'estimator')\n",
    "search.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c6077c-b750-4466-b84f-82a4d3d76fb9",
   "metadata": {},
   "source": [
    "8. **Try combining multiple classifiers, for instance with a [Voting Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier). Can you get a better result?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "964c7069-10d1-41ea-935f-efba059722a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6196969696969697"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vc = VotingClassifier(estimators=[('knn', knn), ('nb', nb), ('svm', svm), ('tree', tree)])\n",
    "vc.fit(X_train, y_train)\n",
    "vc.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
